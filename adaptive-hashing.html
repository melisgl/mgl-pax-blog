<!DOCTYPE html>
<html xmlns='http://www.w3.org/1999/xhtml' xml:lang='en' lang='en'>
<head>
<title>Adaptive Hashing</title>
<link type='text/css' href='style.css' rel='stylesheet'>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width">
<script src="jquery.min.js"></script>
<script src="toc.min.js"></script>
<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         inlineMath: [['$','$']],
         processEscapes: true
       }
     });
   </script>
   <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
   <!-- Google tag (gtag.js) -->
<script async src='https://www.googletagmanager.com/gtag/js?id=G-7X64Q1D73F'></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7X64Q1D73F');
</script>
<script src='grid.js'></script>
<link rel='shortcut icon' type='image/png' href='favicon.png'>
<link rel='preconnect' href='https://fonts.googleapis.com'>
<link rel='preconnect' href='https://fonts.gstatic.com' crossorigin>
<link href='https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap' rel='stylesheet'>
<style> @import url('https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap'); </style>
<link rel='alternate' href='http://quotenil.com/blog.rss' type='application/rss+xml'/>

</head>
<body>
<div id="content-container">
<div id=toc>
 <div id=home>
  <a href=blog.html><code>(QUOTE NIL)</code></a>
 </div>
 <div id=links>
  Ramblings on <a href=ai.html>ai</a>, <a href=lisp.html>lisp</a>, <a href=tech.html>tech</a> 
  and <a href=personal.html>personal</a> topics by <a href=about-me.html>me</a>.
 </div>
</div><div id="content">
<p><a id="x-28MGL-PAX-BLOG-3A-40ADAPTIVE-HASHING-20MGL-PAX-3ASECTION-29"></a>
<a id="MGL-PAX-BLOG:@ADAPTIVE-HASHING%20MGL-PAX:SECTION"></a></p>
<h1><a href="adaptive-hashing.html">Adaptive Hashing</a></h1>
<p><span class='post-data'><em>Tags:</em> <a href="tech.html" title="tech"><code>tech</code></a>, <a href="lisp.html" title="lisp"><code>lisp</code></a>,&nbsp; <em>Date:</em> 2025-05-03</span></p>
<div class='br'></div>
<p>At the <a href="https://www.european-lisp-symposium.org/2024/" >2024 ELS</a>,
I gave a <a href="https://quotenil.com/adaptive-hash-talk.pdf" >talk on adaptive
hashing</a>, which
focusses on making general purpose hash tables <em>faster and more
robust</em> at the same time.</p>
<h2>Theory vs Practice</h2>
<p>Hash table theory most concerns itself with the asymptotic
worst-case cost with a hash function chosen randomly from a family
of hash functions. Although these results are very relevant in
practice,</p>
<ul>
<li><p>those pesky constant factors, that the big-O cost ignores, do
  matter, and</p></li>
<li><p>we don't pick hash functions randomly but fix the hash function
  for the lifetime of the hash table.</p></li>
</ul>
<p>There are <a href="https://en.wikipedia.org/wiki/Perfect_hash_function" >Perfect
Hashing</a>
algorithms, that choose an optimal hash function for a given set of
keys. The drawback is that they either require the set of keys to be
fixed or they are too slow to be used as general purpose hash
tables.</p>
<p>Still, the idea that we can do better by adapting the hash function
to the actual keys is key. Can we do that <em>online</em>, that is, while
the hash table is being used? Potential performance gains come from
improving the constant factors mentioned above by</p>
<ul>
<li><p>having fewer collisions, and</p>

<p><img src="blog-files/cache-friendliness-regret.png" alt="cache-friendliness-regret" /></p></li>
<li><p>being more cache-friendly.</p>

<p><img src="blog-files/cache-friendliness-put.png" alt="cache-friendliness-put" /></p></li>
</ul>
<p>The images above plot regret (the expected number of comparisons of
per lookup minus the minimum achievable) and the measured run-time
of PUT operations vs the number of keys in the hash table with a
particular key distribution. Green is Murmur (a robust hash
function), Blue is SBCL's expedient <code>EQ</code> hash. The
wiggling of the graphs is due to the resizing of the hash table as
keys are added to it.</p>
<p>These gains must more than offset the cost of choosing a hash
function and switching to it, but we have to make some assumption
about the distribution of keys. In fact, some default hash functions
already make such assumptions to make the common cases faster,
usually at the cost of weakened worst-case guarantees.</p>
<h2>Implementation</h2>
<p>The general idea is sound, but turning it into real performance
gains is hard. The rest of this post is about how SBCL's built-in
hash tables, which had been reasonably fast, were modified. The core
switching mechanism looks at</p>
<ul>
<li><p>the length of the collision chain on PUT operations,</p></li>
<li><p>the collision count on rehash (when the hash table is grown), and</p></li>
<li><p>the size of the hash table.</p></li>
</ul>
<h3>Adapting <code>EQ</code> hash tables</h3>
<ol>
<li><p>Init to to constant hash function. This a fancy way of saying
   that we do linear search in a vector internally. This is an <code>EQ</code>
   hash table, so key comparison is as single assembly instruction.</p></li>
<li><p>When the hash table is grown to more than 32 keys and it must be
   rehashed anyway, we switch to a hash function that does a single
   right shift with the number of bits to shift determined from the
   longest common run of low-bits in the keys.</p></li>
<li><p>If too many collisions, we switch to the previous default SBCL
   <code>EQ</code>-hash function that has been tuned for a long time.</p></li>
<li><p>If too many collisions, we switch to Murmur, a general purpose
   hash. We could also go all the way to cryptographic hashes.</p></li>
</ol>
<p>In step 2, the hash function with the single shift fits the memory
allocator's behaviour nicely: it is a perfect hash for keys forming
arithmetic sequences, which is often approximately true for objects
of the same type allocated in a loop.</p>
<p><img src="blog-files/adaptive-hash-eq-put.png" alt="adaptive-hash-eq-put" /></p>
<p>In this figure, the red line is the adaptive hash.</p>
<h3>Adapting <code>EQUAL</code> hash tables</h3>
<p>For composite keys, running the hash function is the main cost.
Adaptive hashing does the following.</p>
<ul>
<li><p>For string keys, hash only the first and last 2 characters.</p></li>
<li><p>For list keys, only hash the first 4 elements.</p></li>
<li><p>If too many collisions, double the limit.</p></li>
</ul>
<p><img src="blog-files/adaptive-hash-string-put.png" alt="adaptive-hash-string-put" /></p>
<p><br>
So, SBCL hash tables have been adaptive for almost a year now,
gaining some speed in common cases, and robustness in others.</p>
<p>The full paper is <a href="https://zenodo.org/records/11091296" >here</a>.</p>
<p><img src="blog-files/adaptive-hash.png" alt="adaptive-hashing" /></p>
<img src="blog-files/die.png" alt="end-of-post" />
  </div>
</div>
<script>$('#page-toc').toc({'selectors': ''});</script>
</body>
</html>
