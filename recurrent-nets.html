<!DOCTYPE html>
<html xmlns='http://www.w3.org/1999/xhtml' xml:lang='en' lang='en'>
<head>
<title>Recurrent Nets
</title>
<link type='text/css' href='style.css' rel='stylesheet'>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width">
   <script src="jquery.min.js"></script>
<script src="toc.min.js"></script>
<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         inlineMath: [['$','$']],
         processEscapes: true
       }
     });
   </script>
   <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
   </script>
   <!-- Google tag (gtag.js) -->
<script async src='https://www.googletagmanager.com/gtag/js?id=G-7X64Q1D73F'></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7X64Q1D73F');
</script>
<script>
function padToBaselineGrid() {
  document.querySelectorAll('pre, img, #toc').forEach(el => {
    if (el.alt == 'end-of-post' || el.alt == 'about-me-die') {
      return;
    }
    // We either add a wrapper div and pad that or pad the element
    // itself.
    let padSelf = (el.id == 'toc');
    let currentHeight = el.getBoundingClientRect().height;
    if (padSelf) {
      var paddingTop = parseFloat(window.getComputedStyle(el).getPropertyValue('padding-top'));
      var paddingBottom = parseFloat(window.getComputedStyle(el).getPropertyValue('padding-bottom'));
      currentHeight -= paddingTop + paddingBottom;
    }
    let lineHeight = parseFloat(window.getComputedStyle(document.body).lineHeight);
    let targetHeight = Math.ceil(currentHeight / lineHeight) * lineHeight;
    let extraPadding = targetHeight - currentHeight;
    if (padSelf) {
      elToPad = el;
    } else {
      if (el.parentNode.className != 'padding-wrapper') {
        w = document.createElement('div');
        w.className = 'padding-wrapper';
        el.replaceWith(w);
        w.appendChild(el);
      }
      if (extraPadding < 0.75*lineHeight) {
        extraPadding += lineHeight;
      }
      elToPad = el.parentNode;
    }
    // Specify padding in rem, so that it scales with font size
    // changes.
    let remPx = parseFloat(getComputedStyle(document.documentElement).fontSize)
    extraPadding = extraPadding / 2 /remPx;
    elToPad.style.paddingTop = `${extraPadding}rem`;
    elToPad.style.paddingBottom = `${extraPadding}rem`;
  });
}
window.addEventListener('load', padToBaselineGrid);
window.addEventListener('resize', padToBaselineGrid);
</script>
<link rel='shortcut icon' type='image/png' href='favicon.png'>
<link rel='preconnect' href='https://fonts.googleapis.com'>
<link rel='preconnect' href='https://fonts.gstatic.com' crossorigin>
<link href='https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap' rel='stylesheet'>
<style> @import url('https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap'); </style>
<link rel='alternate' href='http://quotenil.com/blog.rss' type='application/rss+xml'/>

</head>
<body>
<div id="content-container">
<div id=toc>
 <div id=home>
  <a href=blog.html>(QUOTE NIL)</a>
 </div>
 <div id=links>
  Ramblings on <a href=ai.html>ai</a>, <a href=lisp.html>lisp</a>, <a
  href=tech.html>tech</a> and <a href=personal.html>personal</a> topics by <a
  href=about-me.html>me</a>.
 </div>
</div><div id="content">
<p><a id="x-28MGL-PAX-BLOG-3A-40RECURRENT-NETS-20MGL-PAX-3ASECTION-29"></a>
<a id="MGL-PAX-BLOG:@RECURRENT-NETS%20MGL-PAX:SECTION"></a></p>
<h1><a href="recurrent-nets.html">Recurrent Nets</a></h1>
<p><span class='post-data'><em>Tags:</em> <a href="ai.html" title="ai"><code>ai</code></a>, <a href="lisp.html" title="lisp"><code>lisp</code></a>,&nbsp; <em>Date:</em> 2015-01-19</span></p>
<div class='br'></div>
<p>I've been cleaning up and documenting
<a href="https://github.com/melisgl/mgl" >MGL</a> for quite some time now, and
while it's nowhere near done, a good portion of the code has been
overhauled in the process. There are new additions such as the <a href="http://arxiv.org/abs/1412.6980" >Adam
optimizer</a> and Recurrent Neural
Nets. My efforts were mainly only the backprop stuff and I think the
definition of feed-forward:</p>
<pre><code><span class="code"><span class="paren1">(<span class="code">build-fnn <span class="paren2">(<span class="code"><span class="keyword">:class</span> 'digit-fnn</span>)</span>
  <span class="paren2">(<span class="code">input <span class="paren3">(<span class="code">-&gt;input <span class="keyword">:size</span> <span class="special">*n-inputs*</span></span>)</span></span>)</span>
  <span class="paren2">(<span class="code">hidden-activation <span class="paren3">(<span class="code">-&gt;activation input <span class="keyword">:size</span> n-hiddens</span>)</span></span>)</span>
  <span class="paren2">(<span class="code">hidden <span class="paren3">(<span class="code">-&gt;relu hidden-activation</span>)</span></span>)</span>
  <span class="paren2">(<span class="code">output-activation <span class="paren3">(<span class="code">-&gt;activation hidden <span class="keyword">:size</span> <span class="special">*n-outputs*</span></span>)</span></span>)</span>
  <span class="paren2">(<span class="code">output <span class="paren3">(<span class="code">-&gt;softmax-xe-loss <span class="keyword">:x</span> output-activation</span>)</span></span>)</span></span>)</span></span></code></pre>
<p>and recurrent nets:</p>
<pre><code><span class="code"><span class="paren1">(<span class="code">build-rnn <span class="paren2">(<span class="code"></span>)</span>
  <span class="paren2">(<span class="code">build-fnn <span class="paren3">(<span class="code"><span class="keyword">:class</span> 'sum-sign-fnn</span>)</span>
    <span class="paren3">(<span class="code">input <span class="paren4">(<span class="code">-&gt;input <span class="keyword">:size</span> 1</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">h <span class="paren4">(<span class="code">-&gt;lstm input <span class="keyword">:size</span> n-hiddens</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">prediction <span class="paren4">(<span class="code">-&gt;softmax-xe-loss
                 <span class="paren5">(<span class="code">-&gt;activation h <span class="keyword">:name</span> 'prediction <span class="keyword">:size</span> <span class="special">*n-outputs*</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>
<p>is fairly straight-forward already. There is still much code that
needs to accompany such a network definition, mostly having to do
with how to give inputs and prediction targets to the network and
also with monitoring training. See the full examples for
<a href="https://github.com/melisgl/mgl/blob/master/doc/md/mgl-manual.md#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" >feed-forward</a>
and
<a href="https://github.com/melisgl/mgl/blob/master/doc/md/mgl-manual.md#x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29" >recurrent</a>
nets in the documentation.</p>
<img src="blog-files/die.png" alt="end-of-post" />
  </div>
</div>
<script>$('#page-toc').toc({'selectors': ''});</script>
</body>
</html>
